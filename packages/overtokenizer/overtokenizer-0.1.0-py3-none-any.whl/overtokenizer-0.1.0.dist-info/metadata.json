{"classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "Topic :: Text Processing :: Linguistic", "License :: OSI Approved :: GNU Lesser General Public License v2 or later (LGPLv2+)", "Programming Language :: Python :: 3.5"], "extensions": {"python.commands": {"wrap_console": {"overtokenizer": "overtokenizer:main"}}, "python.details": {"contacts": [{"email": "luismsgomes@gmail.com", "name": "Lu\u00eds Gomes", "role": "author"}], "document_names": {"description": "DESCRIPTION.rst"}, "project_urls": {"Home": "https://bitbucket.org/luismsgomes/overtokenizer"}}, "python.exports": {"console_scripts": {"overtokenizer": "overtokenizer:main"}}}, "extras": [], "generator": "bdist_wheel (0.29.0)", "keywords": ["text", "tokenization", "pre-processing"], "license": "LGPLv2", "metadata_version": "2.0", "name": "overtokenizer", "run_requires": [{"requires": ["docopt", "openfile", "regex"]}], "summary": "Unicode-based language-agnostic (over-) tokenizer.", "version": "0.1.0"}