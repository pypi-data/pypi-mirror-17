#!/usr/bin/python
from __future__ import print_function
try:
    from urllib2 import Request, urlopen
except ImportError:
    from urllib.request import Request, urlopen
import sys
from bs4 import BeautifulSoup


def normalize(text):
    if sys.version_info.major == 3:
        return text.strip()
    else:
        return text.encode("utf-8").strip()


def write_header_gpx(target_file):
    f = open(target_file, 'w')
    f.write('<?xml version=\'1.0\' encoding=\'UTF-8\'?>\n')
    f.write('<gpx version="1.0" creator="HappyCowler" xmlns="http://www.topografix.com/GPX/1/0">\n')
    f.close()


def write_footer_gpx(target_file):
    f = open(target_file, 'a')
    f.write('</gpx>\n')
    f.close()


def append_results_to_file_gpx(target_file, coordinates, names, tags, ratings,
                               addresses, phone_numbers, opening_hours,
                               cuisines, descriptions):
    f = open(target_file, 'a')
    for i in range(len(names)):
        f.write('<wpt lat="' + coordinates[i][0] +
                '" lon="' + coordinates[i][1] + '">\n')
        f.write('    <name>' + names[i].replace('&', 'and') + '</name>\n')
        if "Vegan" in tags[i]:
            f.write('    <extensions><color>#b421880d</color></extensions>\n')
        elif "Vegetarian" in tags[i]:
            f.write('    <extensions><color>#b48a2091</color></extensions>\n')
        elif "Veg-friendly" in tags[i]:
            f.write('    <extensions><color>#b4dc5d5c</color></extensions>\n')
        else:
            f.write('    <extensions><color>#b43775c5</color></extensions>\n')
        f.write('    <desc>\n')
        f.write(addresses[i].replace('&', 'and') + '\n')
        f.write('Phone: ' + phone_numbers[i] + '\n')
        if tags[i] != "":
            f.write('Type: ' + tags[i] + '\n')
        f.write('Rating: ' + ratings[i] + '\n')
        if opening_hours[i] != "" and not "Call for hours" in opening_hours[i]:
            f.write('Hours: ' + opening_hours[i].replace('&', 'and') + '\n')
        else:
            f.write('Hours: unknown\n')
        if cuisines[i] != "":
            f.write(cuisines[i].replace('&', 'and') + '\n')
        f.write('-----\n')
        f.write(descriptions[i].replace('&', 'and') + '\n')
        f.write('    </desc>\n')
        f.write('</wpt>\n')
    f.close()


def write_header_kml(target_file):
    f = open(target_file, 'w')
    f.write('<?xml version=\'1.0\' encoding=\'UTF-8\'?>\n')
    f.write('<kml xmlns="http://earth.google.com/kml/2.1">\n')
    f.write('<Document>\n')
    f.close()


def write_footer_kml(target_file):
    f = open(target_file, 'a')
    f.write('</Document>\n')
    f.write('</kml>\n')
    f.close()


def append_results_to_file_kml(target_file, coordinates, names, tags, ratings,
                               addresses, phone_numbers, opening_hours,
                               cuisines, descriptions):
    f = open(target_file, 'a')
    for i in range(len(names)):
        f.write('  <Placemark>\n')
        f.write('    <name>' + names[i] + '</name>\n')
        f.write('    <Point>\n')
        f.write('      <coordinates>' + coordinates[i][1] + "," +
                coordinates[i][0] + ',0</coordinates>\n')
        f.write('    </Point>\n')
        f.write('   <description>\n')
        f.write('     <![CDATA[ ')
        f.write(addresses[i] + '<br>')
        f.write('<b>Phone:</b> ' + phone_numbers[i] + '<br>')
        f.write('<b><u>Type</u>:</b> ' + tags[i] + ' ')
        f.write('<b><u>Rating</u>:</b> ' + ratings[i] + '<br>')
        f.write('<b><u>Cuisine</u>:</b> ' + cuisines[i] + '<br>')
        f.write('<b><u>Business hours</u>:</b><br> ' + opening_hours[i] + '<br>')
        f.write('<b><u>Description</u>:</b><br> ' + descriptions[i] + '<br>')
        f.write(' ]]>\n')
        f.write('   </description>\n')
        f.write('  </Placemark>\n')
    f.close()


def write_header(target_file):
    if target_file.endswith(".kml"):
        write_header_kml(target_file)
    elif target_file.endswith(".gpx"):
        write_header_gpx(target_file)
    else:
        raise Exception("Unknown filetype")


def write_footer(target_file):
    if target_file.endswith(".kml"):
        write_footer_kml(target_file)
    elif target_file.endswith(".gpx"):
        write_footer_gpx(target_file)
    else:
        raise Exception("Unknown filetype")


def append_results_to_file(target_file, coordinates, names, tags, ratings,
                           addresses, phone_numbers, opening_hours, cuisines,
                           descriptions):
    if target_file.endswith(".kml"):
        append_results_to_file_kml(target_file, coordinates, names, tags,
                                   ratings, addresses, phone_numbers,
                                   opening_hours, cuisines, descriptions)
    elif target_file.endswith(".gpx"):
        append_results_to_file_gpx(target_file, coordinates, names, tags,
                                   ratings, addresses, phone_numbers,
                                   opening_hours, cuisines, descriptions)
    else:
        raise Exception("Unknown filetype")


def parse_restaurant_page(restaurant_url):
    req = Request(restaurant_url, headers={'User-Agent': 'Mozilla/5.0'})
    restaurant_page = urlopen(req).read()
    parsed_restaurant_html = BeautifulSoup(restaurant_page, "html.parser")
    gmap_link = parsed_restaurant_html.find("div",
                                            class_="box-map-links").find('a')
    text_link = gmap_link.attrs["href"]
    start = text_link.find('q=loc:') + 6
    lat, lon = text_link[start:].split('+')
    return (lat, lon)


class HappyCowler(object):

    """Class for obtaining sparse SDP relaxation.

    :param city_url: The URL string for the main page of the city to be
                     crawled.
    :type city_url: str.
    :param target_file: Optional parameter to write the results to a target
                        file.
    :type target_file: str.

    :param verbose: Optional parameter for level of verbosity:

                       * 0: quiet (default)
                       * 1: verbose
    :type verbose: int.
    """
    def __init__(self, city_url, target_file=None, verbose=0):
        """Constructor for the class.
        """
        self.city_url = city_url
        self.target_file = target_file
        self.verbose = verbose
        self.coordinates = []
        self.names = []
        self.tags = []
        self.ratings = []
        self.addresses = []
        self.phone_numbers = []
        self.opening_hours = []
        self.cuisines = []
        self.descriptions = []
        self.processed_entries = 0
        self.total_entries = 0

    def _parse_results_page(self, page_no=''):
        req = Request(self.city_url + page_no,
                      headers={'User-Agent': 'Mozilla/5.0'})
        page = urlopen(req).read()
        parsed_html = BeautifulSoup(page, "html.parser")
        if self.total_entries == 0:
            h1 = parsed_html.body.find('h1').text.strip()
            self.total_entries = int(h1[h1.index("(")+1:h1.index(")")])
        coordinates = []
        names = []
        tags = []
        ratings = []
        addresses = []
        phone_numbers = []
        opening_hours = []
        cuisines = []
        descriptions = []
        for business in parsed_html.body.findAll('div',
                                                 class_="row venue-list-item fg-form"):
            self.processed_entries += 1
            restaurant_url = 'https://www.happycow.net' + \
                business.find('a').get('href')
            coordinates.append(parse_restaurant_page(restaurant_url))
            name = normalize(business.find('a').text)
            if self.verbose > 0:
                percentage = " (done: {:.2%}".format(self.processed_entries /
                                                     self.total_entries)
                msg = "\r\x1b[KCurrent entry: " + name + percentage + ")"
                sys.stdout.write(msg)
                sys.stdout.flush()

            names.append(name)
            tags.append(normalize(business.find('span').text))
            stars = business.find('ul', class_="venue-ratings list-inline")
            if stars is None:
                rating = "unknown"
            else:
                rating = str(len(stars.findAll("i", class_="fa fa-star")) + 0.5*
                             len(stars.findAll("i", class_="fa fa-star-half-o")))
            ratings.append(rating)
            address = None
            for p in business.findAll('p'):
                if p.find('i', class_="fa fa-map-marker"):
                    address = p.text
            if address is not None:
                addresses.append(normalize(address))
            else:
                addresses.append('')
            phone_number = None
            for p in business.findAll('p'):
                if p.find('i', class_="fa fa-phone"):
                    phone_number = p.text
            if phone_number is not None:
                phone_numbers.append(normalize(phone_number))
            else:
                phone_numbers.append('')
            opening_hour = business.find('span', class_='venue-hours-container')
            if opening_hour is not None:
                opening_hours.append(normalize(opening_hour.attrs['data-summary']))
            else:
                opening_hours.append('')
            cuisine = None
            for p in business.findAll('p'):
                if "uisine" in p.text:
                    cuisine = p.text
            if cuisine is not None:
                cuisines.append(normalize(cuisine))
            else:
                cuisines.append('')
            divs = business.findAll("div", class_="col-xs-12")
            description = divs[-1].find('p').text
            if description is not None:
                descriptions.append(normalize(description))
            else:
                description.append('')
        if self.target_file is not None:
            append_results_to_file(self.target_file, coordinates, names, tags,
                                   ratings, addresses, phone_numbers,
                                   opening_hours, cuisines,
                                   descriptions)
        self.coordinates += coordinates
        self.names += names
        self.tags += tags
        self.ratings += ratings
        self.addresses += addresses
        self.phone_numbers += phone_numbers
        self.opening_hours += opening_hours
        self.cuisines += cuisines
        self.descriptions += descriptions
        pagination = parsed_html.body.find('ul', class_="pagination")
        if pagination is not None:
            for a in pagination.findAll('a'):
                if 'aria-label' in a.attrs and a.attrs['aria-label'] == "Next":
                    new_page_no = a.attrs['href']
                    new_page_no = new_page_no[new_page_no.index("?page"):]
                    if page_no != new_page_no:
                        self._parse_results_page(new_page_no)
        else:
            if self.verbose > 0:
                sys.stdout.write("\r")

    def _estimate_number_of_restaurants(self):
        self.total_entries = 0

    def crawl(self):
        """Process a single monomial when building the moment matrix.
        """
        if self.target_file is not None:
            write_header(self.target_file)
        self._parse_results_page("")
        if self.target_file is not None:
            write_footer(self.target_file)


if __name__ == "__main__":
    if len(sys.argv) != 3:
        print("Usage: happycowler city_url output_file")
        exit(-1)
    hc = HappyCowler(sys.argv[1], sys.argv[2], verbose=1)
    hc.crawl()
