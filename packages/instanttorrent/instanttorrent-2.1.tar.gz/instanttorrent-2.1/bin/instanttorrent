#!/usr/bin/python3

import os
import sys
import re
from argparse import ArgumentParser

import requests
from bs4 import BeautifulSoup
from tabulate import tabulate

parser = ArgumentParser()
#parser.add_argument('-m', '--max_results', help='max results to output', type=int, default=10)
parser.add_argument('-q', '--query', help='query to be searched', type=str, default='')
parser.add_argument('-p', '--proxy', help='proxy to access TPB', type=str, default=None)
parser.add_argument('-s','--seeders', help='hide seeders', action='store_false', default=True)
parser.add_argument('-l','--leechers', help='hide leechers', action='store_false', default=True)
parser.add_argument('-d','--date', help='hide upload date', action='store_false', default=True)
parser.add_argument('--size', help='hide file size', action='store_false', default=True)
args = parser.parse_args()

if (sys.version_info < (3,)):
    print('Please run this in python3, python2 is not supported')
    raise SystemExit

class InstantTorrent:
    def __init__(self, proxy):
        self._proxy = self.setup_proxy(proxy)
        self._session = requests.Session()
        self._session.proxies = self._proxy

    def setup_proxy(self, proxy):
        '''
        Sets up your proxy the right way
        '''
        if proxy is None:
            http_proxy = os.environ.get('HTTP_PROXY')
            https_proxy = os.environ.get('HTTPS_PROXY')
            ftp_proxy = os.environ.get('FTP_PROXY')
            return {
                'http': http_proxy,
                'https': https_proxy,
                'ftp': ftp_proxy
            }
        return {
            'http': 'http://' + proxy,
            'https': 'https://' + proxy,
            'ftp': 'ftp://' + proxy
        }

    def output(self, results):
        '''
        :param results: array/list
        dynamically computes and prints wanted user output
        '''
        def make_table():
            '''
            returns table for tabulate
            '''
            table = {'ID': [], 'Title': []}
            if args.seeders is True:
                table['Seed'] = []
            if args.leechers is True:
                table['Leech'] = []
            if args.date is True:
                table['Date'] = []
            if args.size is True:
                table['Size'] = []
            return table

        table = make_table()
        for i, result in enumerate(results):
            table['ID'].append(i)
            table['Title'].append(result[1])
            if args.seeders is True:
                table['Seed'].append(result[2])
            if args.leechers is True:
                table['Leech'].append(result[3])
            if args.date is True:
                table['Date'].append(result[4])
            if args.size is True:
                table['Size'].append(result[5])
        print(tabulate(table, headers='keys'))
        #try:
        #    print('[{}] {}'.format(i, s))
        #except UnicodeEncodeError:
        #    print('[{}] {}'.format(i, s.encode('utf8').decode(sys.stdout.encoding)))
        #    # Python3 encoding fix

    def parse(self, html):
        '''
        parses html output into an array of
        '''
        results = []
        html = BeautifulSoup(html, 'html.parser').findAll('tr')
        def title(html):
            title = html.find(class_='detName').find('a').get_text()
            return title
        def url(html):
            url = html.findAll('a')
            for i in url:
                if 'magnet' in i['href']:
                    url = i['href']
            return url
        def seeders(html):
            seeders = html.findAll('td')[-2:][0].get_text()
            return seeders
        def leechers(html):
            leechers = html.findAll('td')[-2:][1].get_text()
            return leechers
        def date(html):
            date = html.find(class_='detDesc').get_text()
            date = date.split(',')[0].replace('Uploaded ','')
            return date
        def size(html):
            size = html.find(class_='detDesc').get_text()
            size = re.search(r'Size [0-9]+.[0-9]+....', size).group().replace('Size ','')
            return size
        for tag in html:
            try:
                results.append([url(tag), title(tag), seeders(tag), leechers(tag), date(tag), size(tag)])
            except Exception:
                pass
        return results

    def search(self, query):
        url = 'https://thepiratebay.org/search/{}'.format(query)
        r = self._session.get(url)
        results = self.parse(r.content)
        self.output(results)
        try:
            prompt = int(input('> '))
            result = results[prompt][0]#.findAll('a')
        except (ValueError, IndexError):
            raise SystemExit
        return result

    def open_torrent(self, magnet_link):
        if os.name == 'nt':
            os.startfile(magnet_link)  # Windows
        else:
            from subprocess import call
            call(['xdg-open', magnet_link])  # Linux

if __name__ == '__main__':
    bot = InstantTorrent(args.proxy)
    query = args.query
    if query == '':
        print('enter your search query')
        query = input('> ')
    magnet_link = bot.search(query)
    bot.open_torrent(magnet_link)

